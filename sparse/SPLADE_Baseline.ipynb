{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/naver/splade <= 다음 링크를 참조하였습니다\n",
    "# sparse 폴더에 (git clone https://github.com/naver/splade)을 통해 splade 폴더를 생성하세요\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from splade.splade.models.transformer_rep import Splade\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코드 동작에 필요한 필수적인 변수들을 담는 class입니다.\n",
    "class args:\n",
    "    DATA_PATH = \"../data\"\n",
    "    DOCUMENT_NAME = \"DOC_NQ_first64.tsv\"\n",
    "    QUERY_TRAIN_NAME = \"GTQ_NQ_train.tsv\"\n",
    "    QUERY_DEV_NAME = \"GTQ_NQ_dev.tsv\"\n",
    "    TOPK = 1000\n",
    "    SHORT_INFERENCE = True #시간 관계상 모든 dev query를 inferece하지 않고, 100개만 inference하는 경우 사용합니다\n",
    "    SAVE_PATH = \"../data/inference\"\n",
    "    PRED_SAVE_NAME = \"SPLADE_Baseline.json\"\n",
    "    METRIC_SAVE_NAME = \"SPLADE_Result.json\"\n",
    "    MODEL_TYPE_OR_DIR = \"naver/splade_v2_max\" #아래 model list들을 참조하세요\n",
    "\n",
    "#SPLADE는 다양한 버전이 존재합니다. 그중에서, v2의 기본 모델인 splade_v2_max를 사용할 예정입니다.\n",
    "##### v2\n",
    "# model_type_or_dir = \"naver/splade_v2_max\"\n",
    "# model_type_or_dir = \"naver/splade_v2_distil\"\n",
    "##### v2++\n",
    "# model_type_or_dir = \"naver/splade-cocondenser-selfdistil\"\n",
    "#model_type_or_dir = \"naver/splade-cocondenser-ensembledistil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용할 데이터들을 로드한 뒤 전처리합니다. 자세한 내용은 BM25_Baseline을 참조하세요\n",
    "\n",
    "#======================== LOAD AND PREPROCESS ========================================#\n",
    "\n",
    "document_corpus = pd.read_csv(f\"{args.DATA_PATH}/{args.DOCUMENT_NAME}\", sep=\"\\t\", dtype=str)\n",
    "query_train_corpus = pd.read_csv(f\"{args.DATA_PATH}/{args.QUERY_TRAIN_NAME}\", sep=\"\\t\", dtype=str)\n",
    "query_dev_corpus = pd.read_csv(f\"{args.DATA_PATH}/{args.QUERY_DEV_NAME}\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "def clean_text(text):\n",
    "        text = text.replace(\"\\n\", \"\")\n",
    "        text = text.replace(\"``\", \"\")\n",
    "        text = text.replace('\"', \"\")\n",
    "        text = text.replace('\\'', \"\")\n",
    "        return text.lower().strip()\n",
    "\n",
    "#apply clean text\n",
    "document_corpus['query'] = document_corpus['query'].apply(clean_text)\n",
    "query_train_corpus['query'] = query_train_corpus['query'].apply(clean_text)\n",
    "query_dev_corpus['query'] = query_dev_corpus['query'].apply(clean_text)\n",
    "\n",
    "#convert to dict\n",
    "document_corpus = dict(zip(document_corpus[\"oldid\"], document_corpus['query'])) \n",
    "query_train_corpus = dict(zip(query_train_corpus[\"oldid\"], query_train_corpus['query'])) \n",
    "query_dev_corpus = dict(zip(query_dev_corpus[\"oldid\"], query_dev_corpus['query'])) \n",
    "\n",
    "#convert index to document oldid\n",
    "index2oldid = {index: oldid for index, oldid in enumerate(document_corpus.keys())}\n",
    "\n",
    "#======================== LOAD AND PREPROCESS ========================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLADE 모델 및 tokenizer를 hugginface 로부터 load합니다\n",
    "#해당 모델은 MS-Marco dataset으로 pretrained 되어있는 모델입니다.\n",
    "\n",
    "model = Splade(args.MODEL_TYPE_OR_DIR, agg=\"max\")\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.MODEL_TYPE_OR_DIR)\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 추론 및 시각화를 위해 함수 하나를 정의합니다\n",
    "\n",
    "def return_rep_result(query=None,\n",
    "                      doc=None,\n",
    "                      model=model,\n",
    "                      reverse_voc=reverse_voc):\n",
    "    #query 또는 document를 입력으로 받은 뒤, Tuple[sparse_vector, bow_rep, len(bow_rep)]을 return합니다\n",
    "    \n",
    "    #query와 document 중 무엇이 들어왔는지 확인합니다\n",
    "    rep = \"d_rep\" #if doc!=None else \"q_rep\"\n",
    "    _input = doc if doc!=None else query\n",
    "    \n",
    "    #모델을 통과합니다\n",
    "    with torch.no_grad():\n",
    "        input_rep = model(d_kwargs=tokenizer(_input, return_tensors=\"pt\"))[rep].squeeze()  # (sparse) doc rep in voc space, shape (30522,)\n",
    "\n",
    "    #output vector 중 nonzero가 아닌 값들만 list형태로 저장합니다\n",
    "    col = torch.nonzero(input_rep).squeeze().cpu().tolist()\n",
    "\n",
    "    #list 형태로 저장한 col이 각각 어떤 vocab을 의미하고 있는지를 확인합니다\n",
    "    weights = input_rep[col].cpu().tolist()\n",
    "    d = {k: v for k, v in zip(col, weights)}\n",
    "    sorted_d = {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "    bow_rep = []\n",
    "    for k, v in sorted_d.items():\n",
    "        bow_rep.append((reverse_voc[k], round(v, 2)))\n",
    "    \n",
    "    return input_rep, bow_rep, len(bow_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of actual dimensions:  78\n",
      "SPLADE BOW rep:\n",
      " [('thermal', 2.46), ('glass', 2.39), ('stress', 2.32), ('crack', 1.86), ('stressed', 1.56), ('glasses', 1.43), ('pan', 1.43), ('cause', 1.33), ('break', 1.33), ('too', 1.2), ('create', 1.18), ('created', 1.05), ('window', 1.04), ('meaning', 1.04), ('generated', 1.02), ('hot', 0.99), ('area', 0.97), ('shatter', 0.96), ('heat', 0.92), ('formed', 0.92), ('caused', 0.92), ('when', 0.89), ('why', 0.87), ('happen', 0.83), ('collapse', 0.8), ('strike', 0.76), ('produced', 0.69), ('result', 0.68), ('hotter', 0.67), ('adjacent', 0.67), ('cooler', 0.65), ('factor', 0.64), ('determined', 0.64), ('do', 0.64), ('level', 0.63), ('because', 0.62), ('fracture', 0.6), ('material', 0.59), ('if', 0.56), ('materials', 0.56), ('difference', 0.55), ('and', 0.53), ('it', 0.52), ('than', 0.51), ('one', 0.51), ('factors', 0.51), ('temperature', 0.5), ('form', 0.48), ('occur', 0.47), ('related', 0.46), ('generate', 0.44), ('at', 0.44), ('later', 0.43), ('frame', 0.43), ('cold', 0.41), ('pain', 0.41), ('element', 0.41), ('piece', 0.4), ('surrounding', 0.38), ('##e', 0.38), ('governed', 0.36), ('pressure', 0.33), ('problem', 0.24), ('burst', 0.23), ('failure', 0.22), ('originated', 0.2), ('cracking', 0.18), ('great', 0.17), ('ceramic', 0.16), ('effect', 0.16), ('during', 0.13), ('condition', 0.13), ('heated', 0.11), ('crystal', 0.11), ('windows', 0.07), ('change', 0.06), ('fail', 0.04), ('metal', 0.03)]\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.5279, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.5159, 0.0000, 0.0000, 0.4377, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.5103, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "#예시로 document 하나를 넣은 뒤, 어떤 값들이 나오는지 확인합니다\n",
    "#3만 차원의 값들 중 대부분이 0이기 때문에, dense 모델들에 비해 빠른 속도가 특징입니다.\n",
    "\n",
    "doc = \"Glass and Thermal Stress. Thermal Stress is created when one area of a glass pane gets hotter than an adjacent area. If the stress is too great then the glass will crack. The stress level at which the glass will break is governed by several factors.\"\n",
    "sparse_rep, bow_rep, length = return_rep_result(doc=doc)\n",
    "\n",
    "print(\"number of actual dimensions: \", length)\n",
    "print(\"SPLADE BOW rep:\\n\", bow_rep)\n",
    "print(sparse_rep[1980:2030]) #대부분의 값은 0이며, 특정 중요도 이상의 값들만 양수임을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: who has the most title wins in wwe\n",
      "Answer DocID: 65\n",
      "Answer Document: list of wwe champions  the wwe championship is a professional wrestling world heavyweight championship in wwe , currently on the smackdown brand . it is the first world title established in wwe , having been introduced in 1963 as the world wide wrestling federation ( wwwf ) world heavyweight championship . the promotion was renamed world wrestling federation ( wwf ) in 1979 and ended its affiliation with the national wrestling alliance ( nwa ) in 1983 , with the title also renamed to reflect the changes . in 2001 , it was unified with the world championship ( formerly the wcw world heavyweight championship ) following the wwf s buyout of world championship wrestling ( wcw ) and became the undisputed wwf championship . in 2002 , the wwf was renamed world wrestling entertainment ( wwe ) and split its roster into two brands , raw and smackdown . the title , now renamed wwe championship , was then designated to the smackdown brand while wwe established an alternate world title known as the world heavyweight championship for the raw brand . a third alternate world title , the ecw world heavyweight championship , was reactivated for the ecw brand in 2006 . it was vacated and decommissioned when the ecw brand disbanded in 2010 .\n",
      "\n",
      " ======================================== \n",
      "\n",
      "query len: 31, document len: 112\n",
      "query    rep:  [('wwe', 2.22), ('most', 2.11), ('wrestling', 1.76), ('win', 1.76), ('title', 1.74), ('who', 1.47), ('titles', 1.3), ('champion', 1.25), ('has', 1.11), ('championship', 1.09), ('wins', 1.08), ('many', 1.07), ('won', 1.05), ('biggest', 0.99), ('lose', 0.88), ('team', 0.86), ('best', 0.8), ('he', 0.73), ('highest', 0.66), ('success', 0.64), ('fight', 0.62), ('majority', 0.32), ('have', 0.3), ('fame', 0.22), ('raw', 0.22), ('##est', 0.2), ('least', 0.17), ('wwf', 0.16), ('nikki', 0.12), (',', 0.11), ('in', 0.07)]\n",
      "document rep:  [('wwf', 2.45), ('wrestling', 2.06), ('wwe', 2.06), ('championship', 1.94), ('raw', 1.7), ('champion', 1.64), ('wcw', 1.63), ('heavyweight', 1.56), ('champions', 1.39), ('##puted', 1.36), ('world', 1.35), ('title', 1.34), ('federation', 1.32), ('##f', 1.32), ('is', 1.31), ('promotion', 1.27), ('2002', 1.24), ('wide', 1.19), ('alliance', 1.19), ('1963', 1.18), ('smackdown', 1.18), ('year', 1.14), ('was', 1.14), ('became', 1.12), ('formerly', 1.12), ('brand', 1.07), ('established', 1.06), ('team', 1.05), ('first', 1.05), ('introduced', 1.05), ('vacated', 1.0), ('currently', 0.98), ('1980', 0.97), ('wrestler', 0.97), ('nwa', 0.94), ('national', 0.92), ('unified', 0.9), (',', 0.89), ('founded', 0.87), ('meaning', 0.86), ('2001', 0.85), ('august', 0.85), ('retired', 0.81), ('introduce', 0.8), ('start', 0.78), ('renamed', 0.77), ('1979', 0.77), ('worldwide', 0.76), ('1983', 0.7), ('2006', 0.7), ('und', 0.7), ('known', 0.69), ('##w', 0.67), ('titles', 0.62), ('originated', 0.61), ('www', 0.61), ('establish', 0.58), ('ranking', 0.57), ('list', 0.56), ('did', 0.55), ('alternate', 0.5), ('##out', 0.5), ('former', 0.5), ('idea', 0.47), ('disbanded', 0.46), ('wider', 0.44), ('inaugural', 0.43), ('previously', 0.42), ('started', 0.42), ('the', 0.4), ('out', 0.38), ('stable', 0.37), ('representing', 0.36), ('collapsed', 0.34), ('tag', 0.34), ('owned', 0.32), ('ec', 0.32), ('2010', 0.31), ('changed', 0.3), ('folded', 0.28), ('dissolved', 0.28), ('organisation', 0.27), ('created', 0.27), ('espn', 0.26), ('change', 0.26), ('professional', 0.24), ('because', 0.23), ('entertainment', 0.23), ('he', 0.2), ('who', 0.19), ('2008', 0.19), ('brands', 0.18), ('decommissioned', 0.17), ('closed', 0.16), ('formed', 0.14), ('now', 0.14), ('organization', 0.13), ('reactivated', 0.13), ('una', 0.11), ('extinct', 0.1), ('(', 0.1), ('union', 0.09), ('name', 0.08), ('named', 0.08), ('2007', 0.07), ('buy', 0.07), ('leon', 0.05), ('championships', 0.04), ('on', 0.03), ('fame', 0.02), ('reflect', 0.01), ('called', 0.01)]\n"
     ]
    }
   ],
   "source": [
    "#우리 dataset인 NQ320K에 대하여, 임의 query, document에 대해 동일 작업을 수행해 비슷한 결과가 나오는지 확인합니다\n",
    "\n",
    "target = np.random.randint(0,100)\n",
    "answer_docid, train_query = list(query_train_corpus.items())[target]\n",
    "answer_document = document_corpus[answer_docid]\n",
    "\n",
    "query_sparse_rep, query_bow_rep, query_length = return_rep_result(query=train_query)\n",
    "doc_sparse_rep, doc_bow_rep, doc_length = return_rep_result(doc=answer_document)\n",
    "\n",
    "print(f\"Query: {train_query}\")\n",
    "print(f\"Answer DocID: {answer_docid}\")\n",
    "print(f\"Answer Document: {answer_document}\")\n",
    "\n",
    "print(\"\\n\",\"=\"*40,\"\\n\")\n",
    "\n",
    "print(f\"query len: {query_length}, document len: {doc_length}\")\n",
    "print(\"query    rep: \",query_bow_rep)\n",
    "print(\"document rep: \",doc_bow_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splade_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
